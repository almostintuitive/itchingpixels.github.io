<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Why you probably shouldn&rsquo;t trust observational studies 1. Undersampling failure Let&rsquo;s say you&rsquo;re doing research on why certain companies are more successful than others. Your data set only contains successful companies. You&rsquo;ll have a lot of them taking huge risks, that combined with luck created runaway success. And you completely ignored the companies who took huge risks, but weren&rsquo;t lucky enough, and ended up being bankrupt. Your sample naturally overweight the unreasonable risk takers."><meta property="og:title" content="Observational studies"><meta property="og:description" content="Why you probably shouldn&rsquo;t trust observational studies 1. Undersampling failure Let&rsquo;s say you&rsquo;re doing research on why certain companies are more successful than others. Your data set only contains successful companies. You&rsquo;ll have a lot of them taking huge risks, that combined with luck created runaway success. And you completely ignored the companies who took huge risks, but weren&rsquo;t lucky enough, and ended up being bankrupt. Your sample naturally overweight the unreasonable risk takers."><meta property="og:type" content="article"><meta property="og:url" content="https://itchingpixels.com/docs/data/observational-studies/"><meta property="article:published_time" content="2020-07-20T00:00:00+00:00"><meta property="article:modified_time" content="2020-07-20T16:25:22+02:00"><title>Observational studies | Mark Aron Szulyovszky</title><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.63eb88daa545365405ecdbb21033286a325c60a36cfa6d22d21e7c3bc9286941.css integrity="sha256-Y+uI2qVFNlQF7NuyEDMoajJcYKNs+m0i0h58O8koaUE="><script defer src=/en.search.min.2bede241cdaeecbe64ed3371bae073c7729f9427a1f1495073c7d295fa84387c.js integrity="sha256-K+3iQc2u7L5k7TNxuuBzx3KflCeh8UlQc8fSlfqEOHw="></script></head><body><input type=checkbox class=hidden id=menu-control><main class="container flex"><aside class=book-menu><nav><h2 class=book-brand><a href=/><span>Mark Aron Szulyovszky</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><a href=/docs/data/ class=collapsed>Data</a><ul><li><a href=/docs/data/observational-studies/ class=active>Observational studies</a></li></ul></li><li><a href=/docs/technical/ class=collapsed>Technical</a></li><li><a href=/docs/quant/ class=collapsed>(Quantitative) Finance / Investment</a></li><li><a href=/docs/archived-posts/ class=collapsed>Archived posts</a></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Observational studies</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div></header><article class=markdown><h1 id=why-you-probably-shouldnt-trust-observational-studies>Why you probably shouldn&rsquo;t trust observational studies</h1><h3 id=1-undersampling-failure>1. Undersampling failure</h3><p>Let&rsquo;s say you&rsquo;re doing research on why certain companies are more successful than others. Your data set only contains successful companies.
You&rsquo;ll have a lot of them taking huge risks, that combined with luck created runaway success.
And you completely ignored the companies who took huge risks, but weren&rsquo;t lucky enough, and ended up being bankrupt.
Your sample naturally overweight the unreasonable risk takers.
Compare that with a randomized controlled trial, where you start with a set of companies, and observe them throughout their lifetime, so the unreasonable risk takers with less luck will be accounted for.
Then, your conclusions will be more accurate.</p><h3 id=2-overfitting>2. Overfitting</h3><p>The more hypotheses you test on your data, the more likely it is that you&rsquo;ll find a statistically significant effect.
Remember, with a p-value of 0.05, on average, 5 out of every 100 randomly generated hypotheses will test positive.</p><p><a href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124">Research paper: Why Most Published Research Findings Are False</a></p></article><footer class=book-footer><div class="flex justify-between"><div><a class="flex align-center" href=https://github.com/itchingpixels/itchingpixels.github.io/commit/2250aa76626f78d6268b217066897402646ffbd1 title="Last modified by Mark Aron Szulyovszky | 2020 Jul 20" target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt=Calendar>
<span>2020 Jul 20</span></a></div></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div></main></body></html>